# AI RAG核心流程：Indexing与Retrieval模块详解
RAG（Retrieval-Augmented Generation，检索增强生成）的核心流程可分为两大核心阶段：**Indexing（索引构建）** 与**Retrieval（检索）**。其中，Indexing聚焦数据预处理与向量入库，核心是将非结构化数据转化为可高效检索的索引；Retrieval聚焦精准召回与结果提纯，核心是从索引中获取最相关上下文供生成模块使用。以下是两个阶段的完整模块拆解、核心功能及关键技术细节。

## 一、Indexing（索引构建）模块
Indexing是离线预处理流程，核心目标是将原始多源数据转化为结构化、可高效检索的向量索引，为后续在线检索提供数据基础。其包含以下核心模块：

| 模块 | 核心功能 | 关键技术/工具 |
| ---- | ---- | ---- |
| 数据采集与解析 | 收集多源异构数据（文档、PDF、网页、数据库、表格等），解析为统一的文本格式，并提取基础元数据 | 解析工具：Apache Tika、Unstructured、PyPDF2、python-docx；元数据类型：数据来源、创建时间、所属标签、文件类型 |
| 数据清洗与标准化 | 对解析后的文本进行去重、去噪（过滤无效字符、空白内容）、格式统一，同时检测并处理PII（个人身份信息）等敏感数据 | 去重/去噪：正则表达式、NLP清洗库（如NLTK、spaCy）；敏感信息处理：PII检测模型（如Presidio）、数据脱敏工具 |
| 文档分块 | 将长文本切分为语义完整、长度适中的文本块（Chunk），平衡检索精度（小块更精准）与上下文完整性（大块含更多关联信息） | 分块策略：Recursive Character Splitter（递归字符分割）、Semantic Chunker（语义分割）；辅助策略：窗口滑动、重叠率控制（通常10%-20%） |
| 元数据增强 | 为切分后的文本块补充描述性元数据，提升后续检索的过滤能力与相关性判断效率 | 增强方式：LLM生成文本块摘要/主题标签、关键词提取（TF-IDF、RAKE）、实体标注（命名实体识别NER） |
| 向量化（Embedding） | 将文本块转化为高维向量（Embedding），保留文本的语义信息，使机器能够通过向量相似度判断文本相关性 | Embedding模型：Sentence-BERT（如all-MiniLM-L6-v2）、OpenAI Embeddings（text-embedding-3-small）、Llama 2 Embeddings；向量维度：768–4096维（依模型而定） |
| 索引构建 | 构建近似最近邻（ANN）索引，加速向量检索过程，降低在线检索的延迟，提升并发处理能力 | 索引算法：HNSW（层次化近似最近邻）、IVF-PQ（倒排文件+乘积量化）；索引工具：FAISS、Annoy；适配向量数据库：Milvus、Qdrant、Chroma、Pinecone |
| 向量存储 | 将生成的向量与对应的文本块、元数据及索引结构持久化存储，支持高并发读写、水平扩展与数据安全保障 | 存储方案：向量数据库集群部署、冷热数据分层存储（热点数据内存缓存，冷数据磁盘存储）、数据备份与恢复机制 |

## 二、Retrieval（检索）模块
Retrieval是在线查询流程，核心目标是根据用户输入的Query（查询），从已构建的向量索引中高效召回并提纯最相关的上下文信息，为后续LLM生成准确回答提供支撑。其包含以下核心模块：

| 模块 | 核心功能 | 关键技术/工具 |
| ---- | ---- | ---- |
| 查询理解与改写 | 解析用户Query的核心意图，优化Query的表达方式（如补全省略信息、修正歧义、扩展关键词），提升后续召回的相关性 | 核心技术：LLM驱动的Query改写、Query Expansion（查询扩展，如同义词替换、上下文补全）、多轮澄清对话；工具：LangChain Query Transformer、Cohere Query Rewrite |
| 召回（Retrieval） | 基于优化后的Query生成向量，从向量索引中初步获取一批候选文本块（候选集），支持多检索策略并行以提升召回覆盖率 | 检索策略：向量检索（基于余弦相似度、欧氏距离计算）、关键词检索（BM25算法）、混合检索（向量+关键词融合）；加速方式：ANN索引优化 |
| 过滤与剪枝 | 对初步召回的候选集进行筛选，剔除冗余、无关或不符合要求的文本块，减少后续处理压力 | 过滤维度：元数据过滤（标签、来源、时间范围）、权限过滤（访问控制）、相关性阈值过滤；工具：向量数据库内置过滤API |
| 重排序（Reranking） | 采用更精细的相关性模型对筛选后的候选集进行二次排序，提升Top-K结果的相关性精度 | 重排序模型：Cross-Encoder（如ms-marco-MiniLM-L-6-v2、ms-marco-TinyBERT-L-2-v2）、Cohere Rerank、Sentence-BERT Cross-Encoder；策略：截取Top-K（如Top-5、Top-10）结果 |
| 上下文构建 | 将排序后的Top-K文本块进行合并、整理，生成连贯、简洁的上下文内容，同时适配LLM的输入长度限制 | 构建策略：窗口截断（按LLM最大输入长度裁剪）、冗余去重（合并重复信息）、引用标注（标注文本块来源）；工具：LangChain Contextual Compression、LlamaIndex Context Builder |
| 检索评估与反馈 | 离线评估检索效果，在线收集用户反馈，持续优化检索策略与索引构建参数 | 评估指标：MRR（平均倒数排名）、MAP（平均精度均值）、NDCG（归一化折损累积增益）；反馈机制：RLHF（基于人类反馈的强化学习）、用户点击/评分反馈回写索引 |

## 三、关键补充：两阶段的依赖关系与进阶优化
### 1. 核心依赖关系
Indexing阶段的参数选择直接决定Retrieval阶段的效果：① 分块粒度：过细会导致上下文断裂，过粗会降低检索精度；② 向量化模型：模型的语义理解能力决定向量的表征质量，进而影响相似度判断；③ 索引类型：不同ANN索引的检索速度与精度权衡，影响Retrieval的延迟与召回率。
反之，Retrieval阶段的评估结果与用户反馈可反哺Indexing优化，如调整分块大小、更换Embedding模型、优化索引参数等。

### 2. 进阶优化方向
- Indexing进阶：引入知识图谱构建，将文本中的实体、关系转化为知识图谱，增强多跳检索（Multi-hop Retrieval）能力；增加数据增量更新机制，支持实时数据接入与索引动态更新。
- Retrieval进阶：引入查询路由（Query Routing），根据Query类型将其分发至对应的数据索引（如文本索引、表格索引、图片索引）；增加自洽性校验（Self-consistency Check），过滤矛盾的上下文信息，降低LLM生成幻觉的概率。

## 四、关键模块可视化流程图
### 1. Indexing（索引构建）整体流程
```mermaid
graph TD
    A[多源数据采集<br/>（文档/PDF/网页等）] --> B[数据解析与元数据提取]
    B --> C[数据清洗与标准化<br/>（去重/去噪/脱敏）]
    C --> D[文档分块<br/>（语义完整Chunk）]
    D --> E[元数据增强<br/>（摘要/关键词/实体）]
    E --> F[向量化（Embedding）<br/>（文本→高维向量）]
    F --> G[ANN索引构建<br/>（HNSW/IVF-PQ）]
    G --> H[向量与索引持久化存储<br/>（向量数据库集群）]
    H --> I[索引优化/增量更新]